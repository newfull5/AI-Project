{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tokenizer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM7Rq2Ahl99HruSzPJV6znf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/newfull5/AI-Project/blob/master/Tokenizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmfoxd6M46Ld",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#transformers == 2.4.1 으로 수정!\n",
        "!git clone https://github.com/SKT-AI/KoGPT2.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7pMNAQT5ARg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cd KoGPT2 && pip install -r requirements.txt\n",
        "!cd KoGPT2 && pip install ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSzVbx-I5OEp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gluonnlp.data import SentencepieceTokenizer \n",
        "from KoGPT2.kogpt2.utils import get_tokenizer\n",
        "from kogpt2.pytorch_kogpt2 import get_pytorch_kogpt2_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sD4PVgYB5Xxg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model, vocab = get_pytorch_kogpt2_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mo8l3aFw507K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#토큰화와 인덱싱을해서 리턴하는 함수\n",
        "\n",
        "def noveldataset (file_path):\n",
        "  data = []\n",
        "  tokenizer = SentencepieceTokenizer(get_tokenizer())\n",
        "  f = open(file_path,'r',encoding='utf-8')\n",
        "\n",
        "  while True:\n",
        "    file = f.readline()\n",
        "\n",
        "    if not file:\n",
        "      break\n",
        "    line = tokenizer(file)\n",
        "    indexing_word = [vocab[vocab.bos_token]]+ vocab[line] + [vocab[vocab.eos_token]]\n",
        "    data.append(indexing)\n",
        "\n",
        "  f.close()\n",
        "\n",
        "  return data"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}