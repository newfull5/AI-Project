{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pretraining.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNL5foihF2scXoAg8XKyKl/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/newfull5/AI-Project/blob/master/Pretraining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-SfTFYjdqn9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install keras-bert"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9Qc1saadtRD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7b275f9b-cd0b-48f4-d6e3-93e49c0fbc47"
      },
      "source": [
        "from keras_bert import get_base_dict, get_model, compile_model, gen_batch_inputs\n",
        "import keras"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8v2ik6pzfW-4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence_pairs = [\n",
        "    [['all', 'work', 'and', 'no', 'play'], ['makes', 'jack', 'a', 'dull', 'boy']],\n",
        "    [['from', 'the', 'day', 'forth'], ['my', 'arm', 'changed']],\n",
        "    [['and', 'a', 'voice', 'echoed'], ['power', 'give', 'me', 'more', 'power']],\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMBk_5nLfm3j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build token dictionary\n",
        "token_dict = get_base_dict()  # A dict that contains some special tokens\n",
        "for pairs in sentence_pairs:\n",
        "    for token in pairs[0] + pairs[1]:\n",
        "        if token not in token_dict:\n",
        "            token_dict[token] = len(token_dict)\n",
        "token_list = list(token_dict.keys())  # Used for selecting a random word\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42vFP9CKfoyU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5f042a7c-2846-40f7-ff99-8f8b416fb58c"
      },
      "source": [
        "get_base_dict()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'': 0, '[CLS]': 2, '[MASK]': 4, '[SEP]': 3, '[UNK]': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-BEo-SCrm9E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "626b5aaf-ca06-4c86-864a-3ab27291cb34"
      },
      "source": [
        "print(token_dict)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'': 0, '[UNK]': 1, '[CLS]': 2, '[SEP]': 3, '[MASK]': 4, 'all': 5, 'work': 6, 'and': 7, 'no': 8, 'play': 9, 'makes': 10, 'jack': 11, 'a': 12, 'dull': 13, 'boy': 14, 'from': 15, 'the': 16, 'day': 17, 'forth': 18, 'my': 19, 'arm': 20, 'changed': 21, 'voice': 22, 'echoed': 23, 'power': 24, 'give': 25, 'me': 26, 'more': 27}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnCf-X3DquDO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a8cba198-9869-49d4-abd6-1461197a95ae"
      },
      "source": [
        "transfer_model = get_model(\n",
        "    token_num = len(token_dict),\n",
        "    head_num = 5,\n",
        "    transformer_num = 12,\n",
        "    embed_dim=25,\n",
        "    feed_forward_dim = 100,\n",
        "    seq_len=20,\n",
        "    pos_num=20,\n",
        "    dropout_rate=0.05,\n",
        "    \n",
        ")\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "Input-Token (InputLayer)        (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Input-Segment (InputLayer)      (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Token (TokenEmbedding [(None, 20, 25), (28 700         Input-Token[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Segment (Embedding)   (None, 20, 25)       50          Input-Segment[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Token-Segment (Add)   (None, 20, 25)       0           Embedding-Token[0][0]            \n",
            "                                                                 Embedding-Segment[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Position (PositionEmb (None, 20, 25)       500         Embedding-Token-Segment[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Dropout (Dropout)     (None, 20, 25)       0           Embedding-Position[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Norm (LayerNormalizat (None, 20, 25)       50          Embedding-Dropout[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttentio (None, 20, 25)       2600        Embedding-Norm[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttentio (None, 20, 25)       0           Encoder-1-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttentio (None, 20, 25)       0           Embedding-Norm[0][0]             \n",
            "                                                                 Encoder-1-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttentio (None, 20, 25)       50          Encoder-1-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward (FeedForw (None, 20, 25)       5125        Encoder-1-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward-Dropout ( (None, 20, 25)       0           Encoder-1-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward-Add (Add) (None, 20, 25)       0           Encoder-1-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-1-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward-Norm (Lay (None, 20, 25)       50          Encoder-1-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttentio (None, 20, 25)       2600        Encoder-1-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttentio (None, 20, 25)       0           Encoder-2-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttentio (None, 20, 25)       0           Encoder-1-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-2-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttentio (None, 20, 25)       50          Encoder-2-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward (FeedForw (None, 20, 25)       5125        Encoder-2-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward-Dropout ( (None, 20, 25)       0           Encoder-2-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward-Add (Add) (None, 20, 25)       0           Encoder-2-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-2-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward-Norm (Lay (None, 20, 25)       50          Encoder-2-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttentio (None, 20, 25)       2600        Encoder-2-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttentio (None, 20, 25)       0           Encoder-3-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttentio (None, 20, 25)       0           Encoder-2-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-3-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttentio (None, 20, 25)       50          Encoder-3-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward (FeedForw (None, 20, 25)       5125        Encoder-3-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward-Dropout ( (None, 20, 25)       0           Encoder-3-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward-Add (Add) (None, 20, 25)       0           Encoder-3-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-3-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward-Norm (Lay (None, 20, 25)       50          Encoder-3-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttentio (None, 20, 25)       2600        Encoder-3-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttentio (None, 20, 25)       0           Encoder-4-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttentio (None, 20, 25)       0           Encoder-3-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-4-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttentio (None, 20, 25)       50          Encoder-4-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward (FeedForw (None, 20, 25)       5125        Encoder-4-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward-Dropout ( (None, 20, 25)       0           Encoder-4-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward-Add (Add) (None, 20, 25)       0           Encoder-4-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-4-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward-Norm (Lay (None, 20, 25)       50          Encoder-4-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-MultiHeadSelfAttentio (None, 20, 25)       2600        Encoder-4-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-MultiHeadSelfAttentio (None, 20, 25)       0           Encoder-5-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-MultiHeadSelfAttentio (None, 20, 25)       0           Encoder-4-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-5-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-MultiHeadSelfAttentio (None, 20, 25)       50          Encoder-5-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-FeedForward (FeedForw (None, 20, 25)       5125        Encoder-5-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-FeedForward-Dropout ( (None, 20, 25)       0           Encoder-5-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-FeedForward-Add (Add) (None, 20, 25)       0           Encoder-5-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-5-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-FeedForward-Norm (Lay (None, 20, 25)       50          Encoder-5-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-MultiHeadSelfAttentio (None, 20, 25)       2600        Encoder-5-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-MultiHeadSelfAttentio (None, 20, 25)       0           Encoder-6-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-MultiHeadSelfAttentio (None, 20, 25)       0           Encoder-5-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-6-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-MultiHeadSelfAttentio (None, 20, 25)       50          Encoder-6-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-FeedForward (FeedForw (None, 20, 25)       5125        Encoder-6-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-FeedForward-Dropout ( (None, 20, 25)       0           Encoder-6-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-FeedForward-Add (Add) (None, 20, 25)       0           Encoder-6-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-6-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-FeedForward-Norm (Lay (None, 20, 25)       50          Encoder-6-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-MultiHeadSelfAttentio (None, 20, 25)       2600        Encoder-6-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-MultiHeadSelfAttentio (None, 20, 25)       0           Encoder-7-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-MultiHeadSelfAttentio (None, 20, 25)       0           Encoder-6-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-7-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-MultiHeadSelfAttentio (None, 20, 25)       50          Encoder-7-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-FeedForward (FeedForw (None, 20, 25)       5125        Encoder-7-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-FeedForward-Dropout ( (None, 20, 25)       0           Encoder-7-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-FeedForward-Add (Add) (None, 20, 25)       0           Encoder-7-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-7-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-FeedForward-Norm (Lay (None, 20, 25)       50          Encoder-7-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-MultiHeadSelfAttentio (None, 20, 25)       2600        Encoder-7-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-MultiHeadSelfAttentio (None, 20, 25)       0           Encoder-8-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-MultiHeadSelfAttentio (None, 20, 25)       0           Encoder-7-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-8-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-MultiHeadSelfAttentio (None, 20, 25)       50          Encoder-8-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-FeedForward (FeedForw (None, 20, 25)       5125        Encoder-8-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-FeedForward-Dropout ( (None, 20, 25)       0           Encoder-8-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-FeedForward-Add (Add) (None, 20, 25)       0           Encoder-8-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-8-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-FeedForward-Norm (Lay (None, 20, 25)       50          Encoder-8-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-MultiHeadSelfAttentio (None, 20, 25)       2600        Encoder-8-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-MultiHeadSelfAttentio (None, 20, 25)       0           Encoder-9-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-MultiHeadSelfAttentio (None, 20, 25)       0           Encoder-8-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-9-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-MultiHeadSelfAttentio (None, 20, 25)       50          Encoder-9-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-FeedForward (FeedForw (None, 20, 25)       5125        Encoder-9-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-FeedForward-Dropout ( (None, 20, 25)       0           Encoder-9-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-FeedForward-Add (Add) (None, 20, 25)       0           Encoder-9-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-9-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-FeedForward-Norm (Lay (None, 20, 25)       50          Encoder-9-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-MultiHeadSelfAttenti (None, 20, 25)       2600        Encoder-9-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-MultiHeadSelfAttenti (None, 20, 25)       0           Encoder-10-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-MultiHeadSelfAttenti (None, 20, 25)       0           Encoder-9-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-10-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-MultiHeadSelfAttenti (None, 20, 25)       50          Encoder-10-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-FeedForward (FeedFor (None, 20, 25)       5125        Encoder-10-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-FeedForward-Dropout  (None, 20, 25)       0           Encoder-10-FeedForward[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-FeedForward-Add (Add (None, 20, 25)       0           Encoder-10-MultiHeadSelfAttention\n",
            "                                                                 Encoder-10-FeedForward-Dropout[0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-FeedForward-Norm (La (None, 20, 25)       50          Encoder-10-FeedForward-Add[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-MultiHeadSelfAttenti (None, 20, 25)       2600        Encoder-10-FeedForward-Norm[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-MultiHeadSelfAttenti (None, 20, 25)       0           Encoder-11-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-MultiHeadSelfAttenti (None, 20, 25)       0           Encoder-10-FeedForward-Norm[0][0]\n",
            "                                                                 Encoder-11-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-MultiHeadSelfAttenti (None, 20, 25)       50          Encoder-11-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-FeedForward (FeedFor (None, 20, 25)       5125        Encoder-11-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-FeedForward-Dropout  (None, 20, 25)       0           Encoder-11-FeedForward[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-FeedForward-Add (Add (None, 20, 25)       0           Encoder-11-MultiHeadSelfAttention\n",
            "                                                                 Encoder-11-FeedForward-Dropout[0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-FeedForward-Norm (La (None, 20, 25)       50          Encoder-11-FeedForward-Add[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-MultiHeadSelfAttenti (None, 20, 25)       2600        Encoder-11-FeedForward-Norm[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-MultiHeadSelfAttenti (None, 20, 25)       0           Encoder-12-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-MultiHeadSelfAttenti (None, 20, 25)       0           Encoder-11-FeedForward-Norm[0][0]\n",
            "                                                                 Encoder-12-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-MultiHeadSelfAttenti (None, 20, 25)       50          Encoder-12-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-FeedForward (FeedFor (None, 20, 25)       5125        Encoder-12-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-FeedForward-Dropout  (None, 20, 25)       0           Encoder-12-FeedForward[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-FeedForward-Add (Add (None, 20, 25)       0           Encoder-12-MultiHeadSelfAttention\n",
            "                                                                 Encoder-12-FeedForward-Dropout[0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-FeedForward-Norm (La (None, 20, 25)       50          Encoder-12-FeedForward-Add[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "MLM-Dense (Dense)               (None, 20, 25)       650         Encoder-12-FeedForward-Norm[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "MLM-Norm (LayerNormalization)   (None, 20, 25)       50          MLM-Dense[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "Extract (Extract)               (None, 25)           0           Encoder-12-FeedForward-Norm[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "MLM-Sim (EmbeddingSimilarity)   (None, 20, 28)       28          MLM-Norm[0][0]                   \n",
            "                                                                 Embedding-Token[0][1]            \n",
            "__________________________________________________________________________________________________\n",
            "Input-Masked (InputLayer)       (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "NSP-Dense (Dense)               (None, 25)           650         Extract[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "MLM (Masked)                    (None, 20, 28)       0           MLM-Sim[0][0]                    \n",
            "                                                                 Input-Masked[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "NSP (Dense)                     (None, 2)            52          NSP-Dense[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 96,630\n",
            "Trainable params: 96,630\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UubPAOxgsiZ1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 917
        },
        "outputId": "0a58b778-a57b-42db-a183-beca005f63f8"
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1000/1000 [==============================] - 73s 73ms/step - loss: 1.1100 - MLM_loss: 0.4422 - NSP_loss: 0.6678 - val_loss: 1.3799 - val_MLM_loss: 0.4428 - val_NSP_loss: 0.5653\n",
            "Epoch 2/100\n",
            "1000/1000 [==============================] - 61s 61ms/step - loss: 0.9606 - MLM_loss: 0.4401 - NSP_loss: 0.5206 - val_loss: 0.9408 - val_MLM_loss: 0.4470 - val_NSP_loss: 0.3280\n",
            "Epoch 3/100\n",
            "1000/1000 [==============================] - 61s 61ms/step - loss: 0.6744 - MLM_loss: 0.4308 - NSP_loss: 0.2436 - val_loss: 2.2853 - val_MLM_loss: 0.4335 - val_NSP_loss: 0.0721\n",
            "Epoch 4/100\n",
            "1000/1000 [==============================] - 62s 62ms/step - loss: 0.5398 - MLM_loss: 0.4317 - NSP_loss: 0.1081 - val_loss: 0.3499 - val_MLM_loss: 0.4422 - val_NSP_loss: 0.0826\n",
            "Epoch 5/100\n",
            "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5007 - MLM_loss: 0.4266 - NSP_loss: 0.0740 - val_loss: 0.4394 - val_MLM_loss: 0.4241 - val_NSP_loss: 0.0205\n",
            "Epoch 6/100\n",
            "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4802 - MLM_loss: 0.4254 - NSP_loss: 0.0548 - val_loss: 0.4539 - val_MLM_loss: 0.4200 - val_NSP_loss: 0.0145\n",
            "Epoch 7/100\n",
            "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4726 - MLM_loss: 0.4224 - NSP_loss: 0.0502 - val_loss: 0.3325 - val_MLM_loss: 0.4051 - val_NSP_loss: 0.0218\n",
            "Epoch 8/100\n",
            "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4479 - MLM_loss: 0.4084 - NSP_loss: 0.0394 - val_loss: 0.3479 - val_MLM_loss: 0.3932 - val_NSP_loss: 0.0255\n",
            "Epoch 9/100\n",
            "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4498 - MLM_loss: 0.4080 - NSP_loss: 0.0418 - val_loss: 0.2473 - val_MLM_loss: 0.3996 - val_NSP_loss: 0.0048\n",
            "Epoch 10/100\n",
            "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4350 - MLM_loss: 0.3927 - NSP_loss: 0.0423 - val_loss: 0.3498 - val_MLM_loss: 0.3954 - val_NSP_loss: 0.0099\n",
            "Epoch 11/100\n",
            "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4171 - MLM_loss: 0.3947 - NSP_loss: 0.0224 - val_loss: 0.3502 - val_MLM_loss: 0.3666 - val_NSP_loss: 0.0133\n",
            "Epoch 12/100\n",
            "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4122 - MLM_loss: 0.3880 - NSP_loss: 0.0242 - val_loss: 0.3481 - val_MLM_loss: 0.3845 - val_NSP_loss: 0.0024\n",
            "Epoch 13/100\n",
            "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4172 - MLM_loss: 0.3825 - NSP_loss: 0.0347 - val_loss: 0.2362 - val_MLM_loss: 0.3787 - val_NSP_loss: 0.0024\n",
            "Epoch 14/100\n",
            "1000/1000 [==============================] - 61s 61ms/step - loss: 0.3964 - MLM_loss: 0.3749 - NSP_loss: 0.0216 - val_loss: 0.3733 - val_MLM_loss: 0.3513 - val_NSP_loss: 0.0148\n",
            "Epoch 15/100\n",
            "1000/1000 [==============================] - 60s 60ms/step - loss: 0.3897 - MLM_loss: 0.3663 - NSP_loss: 0.0234 - val_loss: 0.3316 - val_MLM_loss: 0.3714 - val_NSP_loss: 0.0117\n",
            "Epoch 16/100\n",
            "1000/1000 [==============================] - 60s 60ms/step - loss: 0.3915 - MLM_loss: 0.3688 - NSP_loss: 0.0226 - val_loss: 0.2577 - val_MLM_loss: 0.3531 - val_NSP_loss: 0.0137\n",
            "Epoch 17/100\n",
            "1000/1000 [==============================] - 60s 60ms/step - loss: 0.3736 - MLM_loss: 0.3575 - NSP_loss: 0.0161 - val_loss: 0.3417 - val_MLM_loss: 0.3557 - val_NSP_loss: 0.0023\n",
            "Epoch 18/100\n",
            "1000/1000 [==============================] - 60s 60ms/step - loss: 0.3588 - MLM_loss: 0.3479 - NSP_loss: 0.0109 - val_loss: 0.2265 - val_MLM_loss: 0.3421 - val_NSP_loss: 0.0074\n",
            "Epoch 19/100\n",
            "1000/1000 [==============================] - 61s 61ms/step - loss: 0.3669 - MLM_loss: 0.3449 - NSP_loss: 0.0220 - val_loss: 0.2211 - val_MLM_loss: 0.3302 - val_NSP_loss: 0.0019\n",
            "Epoch 20/100\n",
            "1000/1000 [==============================] - 61s 61ms/step - loss: 0.3511 - MLM_loss: 0.3382 - NSP_loss: 0.0129 - val_loss: 0.3275 - val_MLM_loss: 0.3089 - val_NSP_loss: 0.0447\n",
            "Epoch 21/100\n",
            "1000/1000 [==============================] - 61s 61ms/step - loss: 0.3486 - MLM_loss: 0.3313 - NSP_loss: 0.0173 - val_loss: 0.2699 - val_MLM_loss: 0.3057 - val_NSP_loss: 0.0245\n",
            "Epoch 22/100\n",
            "1000/1000 [==============================] - 61s 61ms/step - loss: 0.3322 - MLM_loss: 0.3168 - NSP_loss: 0.0154 - val_loss: 0.2897 - val_MLM_loss: 0.3160 - val_NSP_loss: 0.0335\n",
            "Epoch 23/100\n",
            "1000/1000 [==============================] - 61s 61ms/step - loss: 0.3234 - MLM_loss: 0.3132 - NSP_loss: 0.0102 - val_loss: 0.2597 - val_MLM_loss: 0.2987 - val_NSP_loss: 0.0145\n",
            "Epoch 24/100\n",
            "1000/1000 [==============================] - 61s 61ms/step - loss: 0.3081 - MLM_loss: 0.2919 - NSP_loss: 0.0162 - val_loss: 0.3706 - val_MLM_loss: 0.2929 - val_NSP_loss: 0.0031\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkXsMI-WydmY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a6de104e-be98-4091-e50d-10e315b4d444"
      },
      "source": [
        "dir(model)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__call__',\n",
              " '__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getstate__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__setstate__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_add_inbound_node',\n",
              " '_add_unique_metric_name',\n",
              " '_base_init',\n",
              " '_built',\n",
              " '_cache_output_metric_attributes',\n",
              " '_check_trainable_weights_consistency',\n",
              " '_collected_trainable_weights',\n",
              " '_compile_metric_functions',\n",
              " '_compile_metrics',\n",
              " '_compile_weighted_metrics',\n",
              " '_compute_previous_mask',\n",
              " '_expects_training_arg',\n",
              " '_feed_input_names',\n",
              " '_feed_input_shapes',\n",
              " '_feed_inputs',\n",
              " '_feed_loss_fns',\n",
              " '_feed_output_names',\n",
              " '_feed_output_shapes',\n",
              " '_feed_outputs',\n",
              " '_feed_sample_weight_modes',\n",
              " '_feed_sample_weights',\n",
              " '_feed_targets',\n",
              " '_function_kwargs',\n",
              " '_get_callback_model',\n",
              " '_get_existing_metric',\n",
              " '_get_node_attribute_at_index',\n",
              " '_get_training_eval_metrics',\n",
              " '_handle_metrics',\n",
              " '_handle_per_output_metrics',\n",
              " '_inbound_nodes',\n",
              " '_init_graph_network',\n",
              " '_init_subclassed_network',\n",
              " '_initial_weights',\n",
              " '_input_coordinates',\n",
              " '_input_layers',\n",
              " '_is_compiled',\n",
              " '_is_graph_network',\n",
              " '_layers',\n",
              " '_layers_by_depth',\n",
              " '_losses',\n",
              " '_make_predict_function',\n",
              " '_make_test_function',\n",
              " '_make_train_function',\n",
              " '_metrics',\n",
              " '_network_nodes',\n",
              " '_node_key',\n",
              " '_nodes_by_depth',\n",
              " '_non_trainable_weights',\n",
              " '_outbound_nodes',\n",
              " '_output_coordinates',\n",
              " '_output_layers',\n",
              " '_output_loss_metrics',\n",
              " '_output_mask_cache',\n",
              " '_output_shape_cache',\n",
              " '_output_tensor_cache',\n",
              " '_per_input_losses',\n",
              " '_per_input_updates',\n",
              " '_per_output_metrics',\n",
              " '_per_output_weighted_metrics',\n",
              " '_prepare_total_loss',\n",
              " '_set_inputs',\n",
              " '_set_metric_attributes',\n",
              " '_set_per_output_metric_attributes',\n",
              " '_set_sample_weight_attributes',\n",
              " '_standardize_user_data',\n",
              " '_trainable_weights',\n",
              " '_updated_config',\n",
              " '_updates',\n",
              " '_uses_dynamic_learning_phase',\n",
              " '_uses_inputs_arg',\n",
              " '_validate_or_infer_batch_size',\n",
              " 'add_loss',\n",
              " 'add_metric',\n",
              " 'add_update',\n",
              " 'add_weight',\n",
              " 'assert_input_compatibility',\n",
              " 'build',\n",
              " 'built',\n",
              " 'call',\n",
              " 'compile',\n",
              " 'compute_mask',\n",
              " 'compute_output_shape',\n",
              " 'count_params',\n",
              " 'dtype',\n",
              " 'evaluate',\n",
              " 'evaluate_generator',\n",
              " 'fit',\n",
              " 'fit_generator',\n",
              " 'from_config',\n",
              " 'get_config',\n",
              " 'get_input_at',\n",
              " 'get_input_mask_at',\n",
              " 'get_input_shape_at',\n",
              " 'get_layer',\n",
              " 'get_losses_for',\n",
              " 'get_output_at',\n",
              " 'get_output_mask_at',\n",
              " 'get_output_shape_at',\n",
              " 'get_updates_for',\n",
              " 'get_weights',\n",
              " 'history',\n",
              " 'input',\n",
              " 'input_mask',\n",
              " 'input_names',\n",
              " 'input_shape',\n",
              " 'input_spec',\n",
              " 'inputs',\n",
              " 'layers',\n",
              " 'load_weights',\n",
              " 'loss',\n",
              " 'loss_functions',\n",
              " 'loss_weights',\n",
              " 'loss_weights_list',\n",
              " 'losses',\n",
              " 'metrics',\n",
              " 'metrics_names',\n",
              " 'name',\n",
              " 'non_trainable_weights',\n",
              " 'optimizer',\n",
              " 'output',\n",
              " 'output_mask',\n",
              " 'output_names',\n",
              " 'output_shape',\n",
              " 'outputs',\n",
              " 'predict',\n",
              " 'predict_function',\n",
              " 'predict_generator',\n",
              " 'predict_on_batch',\n",
              " 'reset_metrics',\n",
              " 'reset_states',\n",
              " 'run_internal_graph',\n",
              " 'sample_weight_mode',\n",
              " 'sample_weight_modes',\n",
              " 'sample_weights',\n",
              " 'save',\n",
              " 'save_weights',\n",
              " 'set_weights',\n",
              " 'skip_target_indices',\n",
              " 'state_updates',\n",
              " 'stateful',\n",
              " 'stop_training',\n",
              " 'summary',\n",
              " 'supports_masking',\n",
              " 'targets',\n",
              " 'test_function',\n",
              " 'test_on_batch',\n",
              " 'to_json',\n",
              " 'to_yaml',\n",
              " 'total_loss',\n",
              " 'train_function',\n",
              " 'train_on_batch',\n",
              " 'trainable',\n",
              " 'trainable_weights',\n",
              " 'updates',\n",
              " 'uses_learning_phase',\n",
              " 'weights']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoKTutEA5qqq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}